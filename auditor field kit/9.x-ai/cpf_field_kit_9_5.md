# üìã CPF INDICATOR 9.5 FIELD KIT: Uncanny Valley Effects

## ‚ö° QUICK ASSESSMENT (5 minutes)

**Check YES/NO for each:**

‚ñ° **YES/NO**: Organization has written policy requiring AI communications to be labeled as AI-generated
‚ñ° **YES/NO**: Employees have formal process to escalate "something feels wrong" concerns about digital communications
‚ñ° **YES/NO**: Organization requires verification through second channel for high-stakes requests (financial, access, data)
‚ñ° **YES/NO**: Training exists specifically for recognizing AI vs. human communications
‚ñ° **YES/NO**: Security team has documented response procedure for ambiguous AI-human communication reports
‚ñ° **YES/NO**: Technical controls exist that automatically flag or prompt verification for AI-suspicious communications
‚ñ° **YES/NO**: Organization has handled at least one "uncanny" AI communication concern in past 90 days

**Quick Score**: 6-7 YES = Green | 3-5 YES = Yellow | 0-2 YES = Red

---

## üìù EVIDENCE COLLECTION (10 minutes)

### Documents to Request
- **AI Communication Policy**: Written guidelines for AI labeling and verification
- **Training Materials**: Last 6 months of AI recognition training content
- **Incident Reports**: Any reports of "suspicious" or "weird" digital communications
- **Escalation Procedures**: Documented process for ambiguous communication concerns
- **Verification Protocols**: Required steps for high-stakes digital requests

### System Demonstrations
- **"Show me AI labeling"**: How AI-generated communications are marked
- **"Show me escalation"**: How employee reports suspicious communication
- **"Show me verification"**: Process for verifying human identity in requests
- **"Show me monitoring"**: Any technical systems that detect AI characteristics

### Interview Targets
- **IT Security Lead**: Understanding of AI communication threats
- **HR Representative**: Employee training and concern reporting
- **3 Random Employees**: Direct experience with AI interactions and verification
- **Help Desk Staff**: Handling of AI-related user concerns

### System Checks
- **Email/Chat Systems**: Look for AI labeling features or requirements
- **Verification Tools**: Test functionality of secondary verification channels
- **Monitoring Dashboards**: Check for AI interaction monitoring or alerts
- **Training Records**: Verify completion rates for AI recognition training

---

## üéØ RAPID SCORING (2 minutes)

### Decision Tree

**START**: Count total YES answers from Quick Assessment

**IF 0-2 YES answers:**
‚Üí **RED (High Risk)**: No systematic approach to uncanny valley threats

**IF 3-5 YES answers:**
‚Üí Check: *Recent incident handled well?*
   - YES with good outcome ‚Üí **YELLOW (Medium Risk)**
   - NO or poor outcome ‚Üí **RED (High Risk)**

**IF 6-7 YES answers:**
‚Üí Check: *All three present: AI labeling + escalation process + verification protocol?*
   - YES ‚Üí **GREEN (Low Risk)**
   - NO ‚Üí **YELLOW (Medium Risk)**

### Verification Criteria
- **GREEN requires**: AI labeling + escalation process + verification protocol + training + recent successful handling
- **YELLOW flags**: Missing 1-2 critical elements but basic awareness exists  
- **RED flags**: No formal procedures or multiple critical gaps

---

## üîß SOLUTION PRIORITIES (5 minutes)

### HIGH IMPACT / QUICK WINS (Implement First)
- **AI Communication Labeling** | Cost: Low | Time: 2-4 weeks
  - Add "Generated by AI" tags to all automated communications
  - Configure email/chat systems with AI identification
  
- **Escalation Hotline** | Cost: Low | Time: 1-2 weeks  
  - Create simple process for reporting "weird" communications
  - Designate security contact for ambiguous interaction concerns

### MEDIUM IMPACT / MODERATE EFFORT (Implement Second)
- **Two-Channel Verification** | Cost: Medium | Time: 4-6 weeks
  - Require phone/in-person verification for financial requests
  - Implement automatic prompts for high-stakes digital requests
  
- **Basic AI Recognition Training** | Cost: Medium | Time: 3-4 weeks
  - 20-minute module on spotting AI vs. human communications
  - Include "trust your gut" guidance for uncanny interactions

### HIGH IMPACT / LONG-TERM (Strategic Projects)
- **AI Interaction Monitoring** | Cost: High | Time: 8-12 weeks
  - Deploy technical monitoring for uncanny AI communication patterns
  - Implement behavioral analytics for AI interaction anomalies
  
- **Enhanced Authentication** | Cost: High | Time: 10-16 weeks
  - Multi-factor verification triggered by employee uncertainty
  - Biometric confirmation for suspicious video/audio communications

---

## üí¨ CLIENT CONVERSATION (3 minutes)

### Opening Questions
**"Tell me about the last time an employee wasn't sure if they were talking to a person or an AI system."**
- *Follow-up*: "How did they handle that uncertainty?"
- *Red flag*: No examples or dismissive response

**"What happens when someone gets a communication that feels 'off' but they can't explain why?"**
- *Follow-up*: "Do they have someone to ask or a process to follow?"
- *Red flag*: "They figure it out themselves" or no process

**"How do employees verify if a financial or access request is legitimate?"**
- *Follow-up*: "What if it comes through digital channels like email or chat?"
- *Red flag*: Single-channel verification only

### Probing Questions
- **"Do your AI systems identify themselves as artificial?"**
- **"Have you seen any suspicious chatbots or AI-generated communications?"**
- **"How comfortable are employees with AI interactions in general?"**
- **"What's your biggest concern about AI being used against your organization?"**

### Professional Language for Sensitive Topics
- Use: *"Human-AI distinction challenges"* instead of *"uncanny valley effects"*
- Use: *"Authentication uncertainty"* instead of *"psychological discomfort"*
- Use: *"Verification protocols"* instead of *"trust issues"*

---

## üìä FIELD NOTES TEMPLATE

**Assessment Date**: _____________ **Auditor**: _________________

### Quick Assessment Results
‚ñ° AI Labeling Policy: _______ ‚ñ° Escalation Process: _______
‚ñ° Two-Channel Verification: _______ ‚ñ° AI Recognition Training: _______
‚ñ° Security Response Procedure: _______ ‚ñ° Technical Controls: _______
‚ñ° Recent Incident Handling: _______

### Key Evidence Collected
- **Policy Documents**: ________________________________
- **Training Materials**: _________________________________
- **System Demonstrations**: _____________________________
- **Interview Insights**: __________________________________

### Risk Indicators Observed
‚ñ° **High Risk**: No formal procedures, dismissive attitude, no recent incidents handled
‚ñ° **Medium Risk**: Some procedures but gaps, informal processes, inconsistent training
‚ñ° **Low Risk**: Comprehensive approach, documented procedures, proactive awareness

### Immediate Recommendations
1. **Priority 1**: _________________________________________
2. **Priority 2**: _________________________________________  
3. **Priority 3**: _________________________________________

### Follow-up Required
‚ñ° **Technical Assessment**: Detailed system configuration review
‚ñ° **Training Evaluation**: Review training effectiveness and completion
‚ñ° **Policy Review**: Detailed policy gap analysis
‚ñ° **Incident Response Test**: Simulate uncanny AI communication

**Final Score**: ‚ñ° Green ‚ñ° Yellow ‚ñ° Red

**Assessment Time**: _______ minutes **Client Satisfaction**: ‚ñ° High ‚ñ° Medium ‚ñ° Low