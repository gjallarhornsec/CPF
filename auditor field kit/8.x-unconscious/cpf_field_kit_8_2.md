# 📋 CPF INDICATOR 8.2 FIELD KIT
## Unconscious Identification with Threats

---

## ⚡ QUICK ASSESSMENT (5 minutes)

**Check YES/NO for each item observed:**

□ **YES/NO**: Security team requests policy exceptions more frequently than other departments
□ **YES/NO**: Security tools are selected based on "technical appeal" rather than documented business requirements  
□ **YES/NO**: Team spends >70% of professional development time on offensive security training/conferences
□ **YES/NO**: Incident response discussions focus heavily on attack sophistication vs. containment effectiveness
□ **YES/NO**: Security staff use hacker terminology/slang in professional communications with non-technical stakeholders
□ **YES/NO**: External security activities (blogging, research, speaking) lack formal approval documentation
□ **YES/NO**: Recent penetration tests exceeded authorized scope or timeline

**SCORING**: 0-1 YES = GREEN | 2-3 YES = YELLOW | 4+ YES = RED

---

## 📝 EVIDENCE COLLECTION (10 minutes)

### Documents to Request:
- [ ] IT policy exception log (past 12 months) 
- [ ] Security tool purchase/adoption records (past 12 months)
- [ ] Training/conference attendance records for security team
- [ ] 3 most recent incident response reports
- [ ] External activity approval forms for security staff
- [ ] Most recent penetration test scope document and final report

### Demonstrations to Request:
- [ ] "Show me how your team selects new security tools"
- [ ] "Walk me through your last incident response team meeting"
- [ ] "Demonstrate your policy exception approval process"

### System Checks:
- [ ] Review security team workstation configurations for unauthorized tools
- [ ] Check endpoint monitoring coverage on security team devices
- [ ] Verify standard IT request system usage by security staff

### Interview Targets:
- [ ] Security team manager/CISO
- [ ] 2 security team members (different specialties)
- [ ] IT service desk manager
- [ ] Recent incident response team lead

---

## 🎯 RAPID SCORING (2 minutes)

### Decision Tree:

**If ANY of these conditions exist → RED:**
- Security team bypasses standard IT policies regularly
- >80% of training budget spent on offensive security
- External activities show conflict of interest patterns
- Recent security tests exceeded scope without authorization

**If ANY of these conditions exist → YELLOW:**
- Security policy exceptions 2x higher than other departments
- Mixed tool selection criteria (business + technical appeal)
- Incident discussions balance attack analysis with protection focus
- Some informal policy flexibility for security team

**If NONE of above conditions exist → GREEN:**
- Standard policy compliance across all teams
- Business-justified tool selections
- Balanced professional development
- Clear external activity boundaries

---

## 🔧 SOLUTION PRIORITIES (5 minutes)

### HIGH IMPACT / QUICK IMPLEMENTATION
- **Structured Tool Evaluation Process** (Low Cost, 30 days)
  - Require business case for all security tool adoptions
  - Include non-security stakeholders in approval workflow
- **Universal Policy Application** (Low Cost, 15 days)
  - Apply identical exception procedures to all employees
  - Use standard IT request processes for security team

### MEDIUM IMPACT / LONGER TERM  
- **Professional Development Balance** (Medium Cost, 90 days)
  - Implement 60/40 defensive/offensive training split
  - Mandate participation in victim-focused security communities
- **Communication Standards** (Low Cost, 60 days)
  - Create templates emphasizing business impact over technical details
  - Train staff to focus on mitigation rather than attack techniques

### HIGH IMPACT / COMPLEX
- **External Activity Governance** (Medium Cost, 120 days)
  - Require pre-approval for all external security activities
  - Establish clear personal/professional boundary framework
- **Cultural Reinforcement Program** (High Cost, 180 days)
  - Celebrate defensive achievements equally with offensive skills
  - Create advancement criteria rewarding protection-focused behavior

---

## 💬 CLIENT CONVERSATION (3 minutes)

### Opening Questions:
- "How does your security team typically choose new tools and technologies?"
- "What conferences or training events have your security staff attended recently?"
- "Tell me about your most recent security incident response process."

### Follow-up Prompts:
- **If they mention tool enthusiasm**: "What business requirements drove that selection?"
- **If they describe incident response**: "How much time was spent on attack analysis vs. containment?"
- **If they discuss external activities**: "What approval process exists for external security research?"

### Red Flag Indicators Requiring Deeper Investigation:
- **Language**: Excessive use of hacker terminology in professional context
- **Priorities**: Attack sophistication discussed before victim protection
- **Exceptions**: Security team gets different treatment than other employees
- **Boundaries**: Unclear separation between work and personal security activities

### Professional Phrasing for Sensitive Topics:
- Instead of: "Your team identifies with hackers"
- Say: "We're assessing professional boundary maintenance in security roles"
- Instead of: "This creates insider risk"  
- Say: "This pattern can create unintended security exposures"

---

## 📊 FIELD NOTES TEMPLATE

**Assessment Date**: ________________  **Auditor**: ________________

### Quick Assessment Results:
□ Policy exceptions frequency: Normal / Elevated / Excessive
□ Tool selection basis: Business / Mixed / Technical appeal  
□ Training balance: Defensive focus / Balanced / Offensive focus
□ Incident response priority: Protection / Mixed / Analysis focus
□ Communication style: Professional / Mixed / Hacker terminology
□ External activities: Controlled / Unclear / Uncontrolled
□ Testing boundaries: Maintained / Unclear / Exceeded

**Overall Score: GREEN / YELLOW / RED**

### Key Evidence Collected:
- **Policy exceptions**: ________________________________________________
- **Tool decisions**: ___________________________________________________  
- **Training records**: __________________________________________________
- **Incident patterns**: _________________________________________________
- **External activities**: _______________________________________________

### Immediate Recommendations:
**Priority 1** (Implement within 30 days): _______________________________
**Priority 2** (Implement within 90 days): _______________________________  
**Priority 3** (Long-term planning): _____________________________________

### Follow-up Required:
□ Executive briefing needed
□ Additional interviews required
□ System access review needed
□ Policy review recommended
□ Training program assessment needed

**Next Steps**: _______________________________________________________

---

**Field Kit Complete - Total Assessment Time: 22 minutes**