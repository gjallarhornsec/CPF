# üìã CPF INDICATOR 10.8 FIELD KIT
## EMERGENCE UNPREDICTABILITY

---

## ‚ö° QUICK ASSESSMENT (5 minutes)

**Target**: Identify if organization fails to recognize that system interactions create unpredictable security failures.

### Assessment Questions (Yes/No only):

1. **Cross-System Reviews**: Does the organization conduct formal security reviews examining interactions between IT, physical security, HR, and vendor systems at least quarterly?
   - ‚òê Yes ‚òê No

2. **Multi-Factor Incident Analysis**: When security incidents occur, does the organization's standard procedure require analyzing system interactions (not just single root causes)?
   - ‚òê Yes ‚òê No

3. **Combined Change Testing**: Does the organization regularly test security impact of multiple simultaneous changes (software + staff + vendor modifications)?
   - ‚òê Yes ‚òê No

4. **Novel Alert Response**: Does the organization have documented procedures for security alerts that don't match known attack patterns?
   - ‚òê Yes ‚òê No

5. **New Technology Integration**: Does the organization conduct formal security reviews for new technology interactions with existing systems before deployment?
   - ‚òê Yes ‚òê No

6. **Cross-Department Security Protocol**: Do non-IT departments (HR, facilities) have mandatory security review procedures for operational changes?
   - ‚òê Yes ‚òê No

7. **Creative Attack Testing**: Does the organization conduct "red team" exercises exploring novel attack combinations (not just known vulnerabilities) at least annually?
   - ‚òê Yes ‚òê No

---

## üìù EVIDENCE COLLECTION (10 minutes)

### Documents to Request:
- **System Integration Diagrams**: Current network/system dependency maps
- **Incident Response Reports**: Last 3 security incidents (focus on root cause analysis)
- **Change Management Records**: Recent changes affecting multiple systems
- **Security Assessment Reports**: Cross-system security reviews from past 12 months
- **Red Team Exercise Reports**: Creative attack scenario testing results
- **Vendor Risk Assessments**: Third-party security interaction reviews

### Demonstrations to Request:
- **Show monitoring dashboard**: How alerts are categorized and responded to
- **Walk through incident response**: Demonstrate analysis process for complex incidents  
- **Demonstrate change approval**: How multi-system changes get security review
- **Show system dependencies**: How they track interactions between different systems

### System Checks to Perform:
- **Review alert categories**: Check if monitoring includes "unknown pattern" alerts
- **Examine change logs**: Look for simultaneous changes across different systems
- **Check integration points**: Identify system interfaces and security controls
- **Verify communication protocols**: Cross-department security coordination methods

### Key Interview Targets:
- **CISO/Security Manager**: Overall security strategy and incident response
- **IT Operations Manager**: System integration and change management
- **Incident Response Lead**: How complex incidents are analyzed
- **Risk Management Lead**: Cross-system risk assessment approaches

---

## üéØ RAPID SCORING (2 minutes)

### Decision Tree:

**Count "Yes" answers from Quick Assessment:**

- **6-7 Yes** ‚Üí **GREEN (0)**
  - Organization has comprehensive cross-system security awareness
  - Formal procedures for multi-factor analysis exist
  - Regular testing of novel threat combinations

- **3-5 Yes** ‚Üí **YELLOW (1)**  
  - Some cross-system awareness but inconsistent application
  - Incident analysis sometimes considers interactions
  - Informal coordination between departments

- **0-2 Yes** ‚Üí **RED (2)**
  - Focus on individual system security only
  - Single root cause incident analysis
  - Departments operate in security silos

### Objective Thresholds:
- **Cross-system reviews**: Quarterly or more frequent = Green; Annual = Yellow; Less than annual = Red
- **Incident analysis depth**: Multiple factors examined = Green; Sometimes = Yellow; Single cause focus = Red
- **Change testing**: Regular multi-system testing = Green; Occasional = Yellow; Rarely/never = Red

---

## üîß SOLUTION PRIORITY MATRIX (5 minutes)

### HIGH IMPACT / QUICK IMPLEMENTATION:
- **Multi-Factor Incident Response Protocol** (Cost: Low, Time: 30 days)
  - Update incident response checklists to require system interaction analysis
  - Train incident response team on cross-domain investigation
  - No new technology required

### HIGH IMPACT / LONG-TERM:
- **Cross-System Security Integration Platform** (Cost: High, Time: 90 days)
  - Deploy security orchestration tools for dependency mapping
  - Requires vendor selection and system integration
  - Dependencies: Budget approval, technical architecture review

### MEDIUM IMPACT / QUICK IMPLEMENTATION:
- **Change Coordination Security Reviews** (Cost: Low, Time: 45 days)
  - Implement mandatory security reviews for multi-system changes
  - Update change management workflows
  - Dependencies: Process approval, staff training

### MEDIUM IMPACT / LONG-TERM:
- **Emergence Scenario Planning Program** (Cost: Medium, Time: 60 days)
  - Quarterly cross-department security planning workshops
  - Structured scenario development process
  - Dependencies: Staff time allocation, facilitation training

### SUPPORTING SOLUTIONS:
- **Adaptive Monitoring System** (Cost: High, Time: 120 days)
- **Red Team Emergence Testing** (Cost: Medium, Time: Ongoing)

---

## üí¨ CLIENT CONVERSATION SCRIPT (3 minutes)

### Opening Questions:
**"Help me understand your security approach..."**

1. **"When you have a security incident, walk me through exactly how you determine what caused it."**
   - *Follow-up*: "Do you look at what other changes happened around the same time?"

2. **"How do you handle security when you're making changes to multiple systems at once?"**
   - *Follow-up*: "Can you show me your process for that?"

3. **"Tell me about a time when you were surprised by how a security incident unfolded."**
   - *Follow-up*: "What made it unexpected?"

### Red Flag Indicators:
- **"We focus on the root cause"** (single cause thinking)
- **"That's not a security issue, that's [IT/HR/facilities]"** (silo mentality)  
- **"We've never seen that before"** (without investigation process)
- **"Our systems don't interact that way"** (complexity denial)

### Professional Language for Sensitive Topics:
- **Instead of**: "You don't understand system complexity"
- **Say**: "Let's explore how different systems might interact during incidents"

- **Instead of**: "Your thinking is too linear"  
- **Say**: "Consider scenarios where multiple factors combine unexpectedly"

- **Instead of**: "You can't predict emergent threats"
- **Say**: "How do you prepare for security challenges that don't match current patterns?"

---

## üìä FIELD NOTES TEMPLATE

### Assessment Summary:
**Date**: _________________ **Auditor**: _________________
**Organization**: _________________

### Quick Assessment Results:
- Questions 1-7: **___/7 Yes answers**
- **Score: ‚òê Green (0) ‚òê Yellow (1) ‚òê Red (2)**

### Key Evidence Collected:
**Documents Reviewed**: 
- ‚òê System integration diagrams ‚òê Incident reports ‚òê Change management records
- ‚òê Security assessments ‚òê Red team reports ‚òê Vendor assessments

**Demonstrations Observed**:
- ‚òê Monitoring dashboard ‚òê Incident response process
- ‚òê Change approval workflow ‚òê System dependency tracking

### Primary Findings:
**Strengths**:
- _________________________________________________
- _________________________________________________

**Vulnerabilities**:
- _________________________________________________  
- _________________________________________________

**Immediate Risks**:
- _________________________________________________
- _________________________________________________

### Recommended Actions:
**Priority 1 (30 days)**:
- _________________________________________________

**Priority 2 (60 days)**:  
- _________________________________________________

**Priority 3 (90+ days)**:
- _________________________________________________

### Client Response Notes:
**Receptive to findings**: ‚òê Yes ‚òê Partially ‚òê No
**Key concerns raised**: _________________________________
**Implementation barriers**: _____________________________

---

## üöÄ SUCCESS VALIDATION

**Field Kit effectiveness confirmed when:**
- ‚úÖ Assessment completed in under 25 minutes
- ‚úÖ Clear Green/Yellow/Red determination made
- ‚úÖ Specific evidence collected for scoring justification  
- ‚úÖ Actionable recommendations provided to client
- ‚úÖ Client understands findings without psychological theory explanation

**Total Assessment Time**: **22 minutes maximum**